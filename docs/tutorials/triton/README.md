# Triton Tutorials

Welcome to the Triton tutorials for Hexagon-MLIR!

This section contains tutorials showing how to compile and run Python Triton kernels. Start with the vector addition tutorial to understand the basic workflow, then proceed to GELU, Softmax, Flash Attention and Matmul using HexKL for more complex examples.

---

## Available Tutorials

### [Vector Addition](vector_add.md)
### [GELU Activation](gelu.md)
### [Softmax](softmax.md)
### [Flash Attention](flash_attention.md)
### [Matmul HexKL](matmul_hexkl.md)