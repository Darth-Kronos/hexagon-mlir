# ğŸ“ Hexagon-MLIR Tutorials

Welcome to the Hexagon-MLIR tutorials! These hands-on examples will guide you through the process of writing, compiling, and executing Triton kernels and PyTorch models on Qualcomm Hexagon NPUs.

## ğŸƒâ€â™‚ï¸ Quick Start

**[ğŸ“– Start with Triton Tutorials](triton/README.md)**

**[ğŸ“– Start with PyTorch Tutorials](torch-mlir/README.md)**

## ğŸš€ What You'll Learn

These tutorials demonstrate how to leverage Qualcomm's Hexagon NPU targets for AI workloads. You'll discover how to:

### Triton Kernels
- **Write Triton Kernels**: Create kernels that run efficiently on Qualcomm Hexagon NPUs
- **Understand the Compilation Pipeline**: Follow your code from Python through multiple IR transformations to optimized machine code
- **Optimize Performance**: Leverage specific features like multi-threading, vector processing, and memory hierarchy optimization
- **Debug and Profile**: Use built-in tools to analyze and improve your kernel performance

### PyTorch Models
- **Use PyTorch Flow**: Take PyTorch models and compile and execute in our flow
- **Understand the Compilation Pipeline**: Follow your code from Python through multiple IR transformations to optimized machine code

## ğŸ› ï¸ Prerequisites

Before diving into the tutorials, make sure you have:

- âœ… Hexagon-MLIR framework installed ([Installation Guide](../user-guide.md))
- âœ… Python environment with required dependencies
- âœ… Access to Hexagon hardware or simulator
- âœ… Basic understanding of Python and tensor operations
