// RUN: linalg-hexagon-opt %s -pass-pipeline='builtin.module(func.func(conv-tiling{conv-tile-height-dim=true conv-tile-size=8}),\
// RUN: canonicalize)' | FileCheck %s

module {
  func.func @hmx_pipeline_simple(%arg0: memref<1x16x32x128xf16>,
                                 %arg1: memref<224x1x1x128xf16>,
                                 %arg2: memref<1x16x32x224xf16>) {
    %0 = bufferization.to_tensor %arg0 restrict writable : memref<1x16x32x128xf16> to tensor<1x16x32x128xf16>
    %1 = bufferization.to_tensor %arg1 restrict writable : memref<224x1x1x128xf16> to tensor<224x1x1x128xf16>
    %cst = arith.constant 0.000000e+00 : f16
    %2 = tensor.empty() : tensor<1x16x32x224xf16>
    %cst_0 = arith.constant 0.000000e+00 : f16
    %3 = tensor.empty() : tensor<1x2x8x4x8x4x32xf16>
    %pack = linalg.pack %0 padding_value(%cst_0 : f16) inner_dims_pos = [1, 2, 3] inner_tiles = [8, 4, 32]
            into %3 : tensor<1x16x32x128xf16> -> tensor<1x2x8x4x8x4x32xf16>
    %4 = tensor.empty() : tensor<1x2x8x4x8x2x32x2xf16>
    %pack_1 = linalg.pack %pack inner_dims_pos = [5] inner_tiles = [2] into %4
              : tensor<1x2x8x4x8x4x32xf16> -> tensor<1x2x8x4x8x2x32x2xf16>
    %5 = builtin.unrealized_conversion_cast %pack_1 : tensor<1x2x8x4x8x2x32x2xf16> to tensor<1x16x32x128xf16>
    %padded = tensor.pad %1 low[0, 0, 0, 0] high[0, 0, 0, 0] {
    ^bb0(%arg3: index, %arg4: index, %arg5: index, %arg6: index):
      tensor.yield %cst_0 : f16
    } : tensor<224x1x1x128xf16> to tensor<224x1x1x128xf16>
    %c7 = arith.constant 7 : index
    %c32 = arith.constant 32 : index
    %c1 = arith.constant 1 : index
    %c1_2 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %from_elements = tensor.from_elements %c7, %c32, %c1, %c1_2, %c4, %c16, %c2 : tensor<7xindex>
    %reshape = tensor.reshape %padded(%from_elements) : (tensor<224x1x1x128xf16>, tensor<7xindex>)
               -> tensor<7x32x1x1x4x16x2xf16>
    %6 = tensor.empty() : tensor<7x4x1x1x16x32x2xf16>
    %transposed = linalg.transpose ins(%reshape : tensor<7x32x1x1x4x16x2xf16>) outs(%6 : tensor<7x4x1x1x16x32x2xf16>)
                  permutation = [0, 4, 2, 3, 5, 1, 6]
    %7 = builtin.unrealized_conversion_cast %transposed : tensor<7x4x1x1x16x32x2xf16> to tensor<224x1x1x128xf16>
    %8 = tensor.empty() : tensor<1x16x32x224xf16>
    %9 = linalg.conv_2d_nhwc_fhwc ins(%5, %7 : tensor<1x16x32x128xf16>, tensor<224x1x1x128xf16>)
         outs(%8 : tensor<1x16x32x224xf16>) -> tensor<1x16x32x224xf16>
    %10 = builtin.unrealized_conversion_cast %9 : tensor<1x16x32x224xf16> to tensor<1x2x8x7x8x2x32x2xf16>
    %11 = tensor.empty() : tensor<1x2x8x7x8x4x32xf16>
    %unpack = linalg.unpack %10 inner_dims_pos = [5] inner_tiles = [2] into %11
              : tensor<1x2x8x7x8x2x32x2xf16> -> tensor<1x2x8x7x8x4x32xf16>
    %12 = tensor.empty() : tensor<1x16x32x224xf16>
    %unpack_3 = linalg.unpack %unpack inner_dims_pos = [1, 2, 3] inner_tiles = [8, 4, 32] into %12
                : tensor<1x2x8x7x8x4x32xf16> -> tensor<1x16x32x224xf16>
    bufferization.materialize_in_destination %unpack_3 in restrict writable %arg2 : (tensor<1x16x32x224xf16>, memref<1x16x32x224xf16>) -> ()
    return
  }
}

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// The script is designed to make adding checks to
// a test case fast, it is *not* designed to be authoritative
// about what constitutes a good test! The CHECK should be
// minimized and named to reflect the test intent.



// CHECK-LABEL: func.func @hmx_pipeline_simple(
// CHECK-SAME:   %[[ARG0:.*]]: memref<1x16x32x128xf16>,
// CHECK-SAME:   %[[ARG1:.*]]: memref<224x1x1x128xf16>,
// CHECK-SAME:   %[[ARG2:.*]]: memref<1x16x32x224xf16>) {
// CHECK:            %[[RES:.*]] = scf.for [[IDX_0:.*]] = %c0 to %c16 step %c8
// CHECK-SAME:       iter_args([[KERNEL:.*]] = %7) -> (tensor<1x16x32x224xf16>) {

// CHECK-NEXT:       %[[EXTRACT_SLICE_0:.*]] = tensor.extract_slice
// CHECK-SAME:       %4[0, [[IDX_0]], 0, 0] [1, 8, 32, 128] [1, 1, 1, 1] :
// CHECK-SAME:       tensor<1x16x32x128xf16> to tensor<1x8x32x128xf16>

// CHECK-NEXT:       %[[EXTRACT_SLICE_1:.*]] = tensor.extract_slice
// CHECK-SAME:       [[KERNEL]][0, [[IDX_0]], 0, 0] [1, 8, 32, 224] [1, 1, 1, 1] :
// CHECK-SAME:       tensor<1x16x32x224xf16> to tensor<1x8x32x224xf16>

// CHECK-NEXT:       %[[CONV_RES:.*]] = linalg.conv_2d_nhwc_fhwc ins(
// CHECK-SAME:       %[[EXTRACT_SLICE_0]], %[[FILTER:.*]] : tensor<1x8x32x128xf16>, tensor<224x1x1x128xf16>)
// CHECK-SAME:       outs(%[[EXTRACT_SLICE_1]] : tensor<1x8x32x224xf16>) -> tensor<1x8x32x224xf16>

// CHECK-NEXT:       %[[INSERT_SLICE:.*]] = tensor.insert_slice
// CHECK-SAME:       %[[CONV_RES]] into [[KERNEL]][0, [[IDX_0]], 0, 0] [1, 8, 32, 224] [1, 1, 1, 1] :
// CHECK-SAME:       tensor<1x8x32x224xf16> into tensor<1x16x32x224xf16>

// CHECK-NEXT:       scf.yield %[[INSERT_SLICE]] : tensor<1x16x32x224xf16>
// CHECK-NEXT:     }
// CHECK:          return
// CHECK-NEXT:   }